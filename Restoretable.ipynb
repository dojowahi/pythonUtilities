{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from airflow.hooks.mysql_hook import MySqlHook\n",
    "import logging\n",
    "from datetime import datetime,timezone\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s', level=logging.INFO, datefmt='%Y-%m-%d %H:%M:%S')\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "class RestoreTables:\n",
    "    __schema_name = None\n",
    "    __table_name = None\n",
    "    msc = None\n",
    "    \n",
    "    def __init__(self, table, msc, client):\n",
    "        self.__schema_name = table.split('.')[0]\n",
    "        self.__table_name_name = table.split('.')[1]\n",
    "        self.msc = msc\n",
    "        self.s3_client = client\n",
    "        self.s3_bucket = None\n",
    "        \n",
    "        \n",
    "    def get_partitions(self):\n",
    "        get_partition_query = \"\"\"\n",
    "        select PART_NAME FROM hive.PARTITIONS WHERE \n",
    "        TBL_ID=(SELECT tbl_id FROM hive.TBLS t, hive.DBS d WHERE t.TBL_NAME=%s and t.DB_ID=d.DB_ID and d.NAME=%s);\"\"\"\n",
    "        param = (self.__table_name_name,self.__schema_name)\n",
    "        return self.msc.get_pandas_df(get_partition_query, param)\n",
    "    \n",
    "    def get_table_location(self):\n",
    "        get_table_location = \"\"\"\n",
    "        SELECT location FROM hive.TBLS t JOIN hive.DBS d ON t.DB_ID = d.DB_ID JOIN hive.SDS s ON t.SD_ID = s.SD_ID\n",
    "        WHERE TBL_NAME = %s AND d.NAME= %s\"\"\"\n",
    "        param = (self.__table_name_name,self.__schema_name)\n",
    "        return self.msc.get_pandas_df(get_table_location, param)\n",
    "    \n",
    "    def get_versioned_obj(self):\n",
    "        restore_list = []\n",
    "        partition_df = self.get_partitions()\n",
    "        location_df = self.get_table_location()\n",
    "        print(\"Location:\",location_df['location'][0])\n",
    "        self.s3_bucket = location_df['location'][0].split('/')[2]\n",
    "        starting_prefix = location_df['location'][0].split('/')[3]\n",
    "        total_partitions = len(partition_df.index)\n",
    "        for row, record in partition_df.iterrows():\n",
    "            prefix = starting_prefix +'/'+ record['PART_NAME'] \n",
    "            try:\n",
    "                response = self.s3_client.list_object_versions(Bucket=self.s3_bucket,Prefix=prefix)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('\\nError for: {0}'.format(response))\n",
    "                raise e\n",
    "            else:        \n",
    "                if 'DeleteMarkers' in response:\n",
    "                    logging.info('Processing {0}/{1}:{2}'.format(row+1, total_partitions, prefix ))\n",
    "                    for markers in response['DeleteMarkers']:\n",
    "                        if markers['IsLatest']:\n",
    "                            restore_list.append((markers['Key'],markers['VersionId']))\n",
    "        return restore_list      \n",
    "    \n",
    "    def restore_objects(self,s3_obj):\n",
    "        logging.info(\"Restoring object:\",s3_obj)\n",
    "        key = s3_obj[0]\n",
    "        versionid = s3_obj[1]\n",
    "        response = self.s3_client.delete_object(Bucket=self.s3_bucket,Key=key,VersionId=versionid)\n",
    "        return response\n",
    "        \n",
    "\n",
    "            \n",
    "msc = MySqlHook('etl_metastore')\n",
    "s3_client = boto3.client('s3')\n",
    "table_list = ['company.cust_orders']\n",
    "restore_list=[]\n",
    "\n",
    "# response =s3_client.list_object_versions(Bucket='xst_hive-prd-data', Prefix= 'cust_orders/date_key=20160618/ver=1')\n",
    "# if 'DeleteMarkers' in response:\n",
    "#     for markers in response['DeleteMarkers']:\n",
    "#         if markers['IsLatest']:\n",
    "#             print(\"Key:\",markers['Key'])\n",
    "#             print(\"Version:\",markers['VersionId'])\n",
    "# else:\n",
    "#     print(\"No versioned data\")\n",
    "\n",
    "for table in table_list:\n",
    "    rt = RestoreTables(table,msc,s3_client)\n",
    "    list_restore = rt.get_versioned_obj()\n",
    "    if list_restore:\n",
    "        logging.info(\"Objects to be restored:\",len(list_restore))\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            executor.map(rt.restore_objects, list_restore)\n",
    "#         for obj in list_restore:\n",
    "#             rt.restore_objects(obj)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
